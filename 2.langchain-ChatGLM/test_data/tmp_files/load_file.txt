filepath=test_data/README_en.md,len=120
page_content='ChatGLM Application with Local Knowledge Implementation' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Introduction' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🌍 中文文档' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🤖️ This is a ChatGLM application based on local knowledge, implemented using ChatGLM-6B and langchain.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content="💡 Inspired by document.ai and Alex Zhangji's ChatGLM-6B Pull Request, this project establishes a local knowledge question-answering application using open-source models." metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='✅ The embeddings used in this project are GanymedeNil/text2vec-large-chinese, and the LLM is ChatGLM-6B. Relying on these models, this project enables the use of open-source models for offline private deployment.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='⛓️ The implementation principle of this project is illustrated in the figure below. The process includes loading files -> reading text -> text segmentation -> text vectorization -> question vectorization -> matching the top k most similar text vectors to the question vector -> adding the matched text to prompt along with the question as context -> submitting to LLM to generate an answer.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='🚩 This project does not involve fine-tuning or training; however, fine-tuning or training can be employed to optimize the effectiveness of this project.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='📓 ModelWhale online notebook' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Changelog' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='[2023/04/15]' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'UncategorizedText'}
page_content='refactor the project structure to keep the command line demo cli_demo.py and the Web UI demo webui.py in the root directory.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Improve the Web UI by modifying it to first load the model according to the default option of configs/model_config.py after running the Web UI, and adding error messages, etc.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Update FAQ.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[2023/04/12]' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'UncategorizedText'}
page_content='Replaced the sample files in the Web UI to avoid issues with unreadable files due to encoding problems in Ubuntu;' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Replaced the prompt template in knowledge_based_chatglm.py to prevent confusion in the content returned by ChatGLM, which may arise from the prompt template containing Chinese and English bilingual text.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[2023/04/11]' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'UncategorizedText'}
page_content='Added Web UI V0.1 version (thanks to @liangtongt);' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Added Frequently Asked Questions in README.md (thanks to @calcitem and @bolongliu);' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Enhanced automatic detection for the availability of cuda, mps, and cpu for LLM and Embedding model running devices;' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Added a check for filepath in knowledge_based_chatglm.py. In addition to supporting single file import, it now supports a single folder path as input. After input, it will traverse each file in the folder and display a command-line message indicating the success of each file load.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[2023/04/09]' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Replaced the previously selected ChatVectorDBChain with RetrievalQA in langchain, effectively reducing the issue of stopping due to insufficient video memory after asking 2-3 times;' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Added EMBEDDING_MODEL, VECTOR_SEARCH_TOP_K, LLM_MODEL, LLM_HISTORY_LEN, REPLY_WITH_SOURCE parameter value settings in knowledge_based_chatglm.py;' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Added chatglm-6b-int4 and chatglm-6b-int4-qe, which require less GPU memory, as LLM model options;' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Corrected code errors in README.md (thanks to @calcitem).' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[2023/04/07]' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'UncategorizedText'}
page_content='Resolved the issue of doubled video memory usage when loading the ChatGLM model (thanks to @suc16 and @myml);' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Added a mechanism to clear video memory;' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Added nghuyong/ernie-3.0-nano-zh and nghuyong/ernie-3.0-base-zh as Embedding model options, which consume less video memory resources than GanymedeNil/text2vec-large-chinese (thanks to @lastrei).' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='How to Use' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Hardware Requirements' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B Model Hardware Requirements\n| Quantization Level | Minimum GPU Memory (inference) | Minimum GPU Memory (efficient parameter fine-tuning) |\n | -------------- | ------------------------- | --------------------------------- |\n | FP16 (no quantization) | 13 GB | 14 GB |\n | INT8 | 8 GB | 9 GB |\n | INT4 | 6 GB | 7 GB |' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Embedding Model Hardware Requirements\nThe default Embedding model GanymedeNil/text2vec-large-chinese in this project occupies around 3GB of video memory and can also be configured to run on a CPU.\nSoftware Requirements' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='This repository has been tested with Python 3.8 and CUDA 11.7 environments.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='1. Setting up the environment' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Environment check' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='```shell' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='First, make sure your machine has Python 3.8 or higher installed' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ python --version\nPython 3.8.13' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='If your version is lower, you can use conda to install the environment' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'UncategorizedText'}
page_content='$ conda create -p /your_path/env_name python=3.8' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Activate the environment' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ source activate /your_path/env_name' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Deactivate the environment' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ source deactivate /your_path/env_name' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Remove the environment' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ conda env remove -p  /your_path/env_name\n```' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Project dependencies' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='```shell' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Clone the repository' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ git clone https://github.com/imClumsyPanda/langchain-ChatGLM.git' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Install dependencies' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ pip install -r requirements.txt\n```' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Note: When using langchain.document_loaders.UnstructuredFileLoader for unstructured file integration, you may need to install other dependency packages according to the documentation. Please refer to langchain documentation.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='2. Run Scripts to Experience Web UI or Command Line Interaction' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Execute webui.py script to experience Web interaction \n```commandline\npython webui.py' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Or execute [api.py](api.py) script to deploy web api.shell\n$ python api.py\n``\nNote: Before executing, check the remaining space in the$HOME/.cache/huggingface/` folder, at least 15G.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Or execute following command to run VUE after api.py executed\n```shell\n$ cd views' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='$ pnpm i' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ npm run dev\n```' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='VUE interface screenshots:' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Web UI interface screenshots:' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='The Web UI supports the following features:' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Automatically reads the LLM and embedding model enumerations in configs/model_config.py, allowing you to select and reload the model by clicking 重新加载模型.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='The length of retained dialogue history can be manually adjusted according to the available video memory.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Adds a file upload function. Select the uploaded file through the drop-down box, click 加载文件 to load the file, and change the loaded file at any time during the process.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Alternatively, execute the knowledge_based_chatglm.py script to experience command line interaction:' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='commandline\npython knowledge_based_chatglm.py' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='FAQ' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Q1: What file formats does this project support?' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='A1: Currently, this project has been tested with txt, docx, and md file formats. For more file formats, please refer to the langchain documentation. It is known that if the document contains special characters, there might be issues with loading the file.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Q2: How can I resolve the detectron2 dependency issue when reading specific file formats?' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='A2: As the installation process for this package can be problematic and it is only required for some file formats, it is not included in requirements.txt. You can install it with the following command:' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='commandline\npip install "detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2"' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Q3: How can I solve the Resource punkt not found. error?' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='A3: Unzip the packages/tokenizers folder from https://github.com/nltk/nltk_data/raw/gh-pages/packages/tokenizers/punkt.zip, and place it in the nltk_data/tokenizers storage path.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='The nltk_data storage path can be found using nltk.data.path.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Q4: How can I solve the Resource averaged_perceptron_tagger not found. error?' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='A4: Download https://github.com/nltk/nltk_data/blob/gh-pages/packages/taggers/averaged_perceptron_tagger.zip, extract it, and place it in the nltk_data/taggers storage path.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='The nltk_data storage path can be found using nltk.data.path.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Q5: Can this project run in Google Colab?' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content="A5: You can try running the chatglm-6b-int4 model in Google Colab. Please note that if you want to run the Web UI in Colab, you need to set the share parameter in demo.queue(concurrency_count=3).launch(server_name='0.0.0.0', share=False, inbrowser=False) to True." metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='This issue is related to the system environment. For more details, please refer to Issues with installing packages using pip in Anaconda.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='DEMO' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Using the question "What are the limitations of ChatGLM-6B and how can they be improved?" as an example:' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Without using langchain to access local documents:' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='ChatGLM-6B is a chatbot based on GPT-3, and its limitations are mainly reflected in the following aspects:' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Language model accuracy: Although GPT-3 is a large language model with relatively high accuracy, it still has some limitations. For instance, it may not be able to accurately understand certain dialects, accents, or complex sentence structures.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Completeness of the knowledge graph: GPT-3 can generate some knowledge graphs, but its completeness and accuracy may not be sufficient. For example, it may struggle to accurately understand specific domain expertise and terminology.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content="Coherence of dialogue generation: While GPT-3 can generate somewhat coherent dialogues, they may not always be natural. For instance, it may generate false, incoherent dialogue or misinterpret the user's intent." metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='To improve ChatGLM-6B, consider the following aspects:' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Enhance the accuracy of the language model: The accuracy of the language model can be improved by increasing the training data, using better language model architectures, and optimizing the model training process.' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content="Strengthen the integrity of the knowledge graph: The integrity of the knowledge graph can be enhanced by increasing its dimensions, employing better knowledge graph construction methods, and optimizing the knowledge graph's matching algorithm." metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content="Boost the coherence of dialogue generation: The coherence of dialogue generation can be improved by augmenting the context information of the dialogue generation model, utilizing better context information extraction methods, and optimizing the dialogue generation model's algorithm." metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content="Incorporate more human feedback: Human feedback can help ChatGLM-6B better understand users' intentions and needs, thereby improving the quality and accuracy of dialogue generation. More human feedback can be introduced by involving more human agents and using human feedback collectors." metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content="ChatGLM's answer after using LangChain to access the README.md file of the ChatGLM-6B project:" metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content="ChatGLM-6B is a deep learning-based natural language processing model that excels at answering questions. However, it also has some limitations, as follows:\n1. Limited language understanding: ChatGLM-6B has been primarily trained on Chinese natural language, and its understanding of other languages may be limited.\n2. Insufficient knowledge base: The training dataset of ChatGLM-6B contains only a Chinese corpus, so it may not be able to answer non-Chinese questions or queries in specific domains.\n3. Limited data volume: ChatGLM-6B's training dataset has only a few million records, which may hinder its ability to answer very specific or complex questions." metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content="To improve ChatGLM-6B, consider the following aspects:\n1. Expand language knowledge: Learn natural language processing techniques in other languages to broaden the model's language understanding capabilities.\n2. Broaden the knowledge base: Collect more Chinese corpora or use datasets in other languages to expand the model's knowledge base.\n3. Increase data volume: Use larger datasets to train ChatGLM-6B, which can improve the model's performance.\n4. Introduce more evaluation metrics: Incorporate additional evaluation metrics to assess the model's performance, which can help identify the shortcomings and limitations of ChatGLM-6B.\n5. Enhance the model architecture: Improve ChatGLM-6B's model architecture to boost its performance and capabilities. For example, employ larger neural networks or refined convolutional neural network structures." metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Roadmap' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='[x] Implement LangChain + ChatGLM-6B for local knowledge application' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] Unstructured file access based on langchain' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x].md' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x].pdf' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x].docx' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x].txt' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Add support for more LLM models' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b-int4' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b-int4-qe' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Add Web UI DEMO' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] Implement Web UI DEMO using Gradio' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] Add output and error messages' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] Citation callout' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Knowledge base management\n[x] QA based on selected knowledge base\n[x] Add files/folder to knowledge base\n[ ] Add files/folder to knowledge base' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Implement Web UI DEMO using Streamlit' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Add support for API deployment' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] Use fastapi to implement API' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Implement Web UI DEMO for API calls' metadata={'source': 'test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
filepath=test_data/README.md,len=116
page_content='基于本地知识库的 ChatGLM 等大语言模型应用实现' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='介绍' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🌍 READ THIS IN ENGLISH' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🤖️ 一种利用 langchain 思想实现的基于本地知识库的问答应用，目标期望建立一套对中文场景与开源模型支持友好、可离线运行的知识库问答解决方案。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='GanymedeNil 的项目' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='document.ai 和' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='AlexZhangji 创建的' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B Pull Request 启发，建立了全流程可使用开源模型实现的本地知识库问答应用。现已支持使用' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B 等大语言模型直接接入，或通过' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='fastchat api 形式接入 Vicuna, Alpaca, LLaMA, Koala, RWKV 等模型。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='✅ 本项目中 Embedding 默认选用的是 GanymedeNil/text2vec-large-chinese，LLM 默认选用的是 ChatGLM-6B。依托上述模型，本项目可实现全部使用开源模型离线私有部署。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='⛓️ 本项目实现原理如下图所示，过程包括加载文件 -> 读取文本 -> 文本分割 -> 文本向量化 -> 问句向量化 -> 在文本向量中匹配出与问句向量最相似的top k个 -> 匹配出的文本作为上下文和问题一起添加到prompt中 -> 提交给LLM生成回答。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'UncategorizedText'}
page_content='📺 原理介绍视频' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='从文档处理角度来看，实现流程如下：' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🚩 本项目未涉及微调、训练过程，但可利用微调或训练对本项目效果进行优化。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🐳\xa0Docker镜像：registry.cn-beijing.aliyuncs.com/isafetech/chatmydata:1.0\xa0（感谢\xa0@InkSong🌲 ）' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='💻\xa0运行方式：docker\xa0run\xa0-d\xa0-p\xa080:7860\xa0--gpus\xa0all\xa0registry.cn-beijing.aliyuncs.com/isafetech/chatmydata:1.0' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='🌐 AutoDL 镜像' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='📓 ModelWhale 在线运行项目' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='变更日志' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='参见 版本更新日志。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='硬件需求' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B 模型硬件需求\n注：如未将模型下载至本地，请执行前检查$HOME/.cache/huggingface/文件夹剩余空间，模型文件下载至本地需要 15 GB 存储空间。\n注：一些其它的可选启动项见项目启动选项\n模型下载方法可参考 常见问题 中 Q8。\n| 量化等级   | 最低 GPU 显存（推理） | 最低 GPU 显存（高效参数微调） |\n| -------------- | ------------------------- | --------------------------------- |\n| FP16（无量化） | 13 GB                     | 14 GB                             |\n| INT8           | 8 GB                     | 9 GB                             |\n| INT4           | 6 GB                      | 7 GB                              |' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='MOSS 模型硬件需求\n注：如未将模型下载至本地，请执行前检查$HOME/.cache/huggingface/文件夹剩余空间，模型文件下载至本地需要 70 GB 存储空间\n模型下载方法可参考 常见问题 中 Q8。\n| 量化等级  | 最低 GPU 显存（推理） | 最低 GPU 显存（高效参数微调） |\n|-------------------|-----------------------| --------------------------------- |\n| FP16（无量化） | 68 GB             | -                     |\n| INT8      | 20 GB          | -                     |' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Embedding 模型硬件需求\n本项目中默认选用的 Embedding 模型 GanymedeNil/text2vec-large-chinese 约占用显存 3GB，也可修改为在 CPU 中运行。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Docker 整合包' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🐳 Docker镜像地址：registry.cn-beijing.aliyuncs.com/isafetech/chatmydata:1.0🌲' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='💻 一行命令运行：\nshell\ndocker run -d -p 80:7860 --gpus all registry.cn-beijing.aliyuncs.com/isafetech/chatmydata:1.0' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='该版本镜像大小25.2G，使用v0.1.16，以nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04为基础镜像' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='该版本内置两个embedding模型：m3e-base，text2vec-large-chinese，内置fastchat+chatglm-6b' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='该版本目标为方便一键部署使用，请确保您已经在Linux发行版上安装了NVIDIA驱动程序' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='请注意，您不需要在主机系统上安装CUDA工具包，但需要安装NVIDIA Driver以及NVIDIA Container Toolkit，请参考安装指南' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='首次拉取和启动均需要一定时间，首次启动时请参照下图使用docker logs -f <container id>查看日志' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='如遇到启动过程卡在Waiting..步骤，建议使用docker exec -it <container id> bash进入/logs/目录查看对应阶段日志' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Docker 部署' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='为了能让容器使用主机GPU资源，需要在主机上安装 NVIDIA Container Toolkit。具体安装步骤如下：\nshell\nsudo apt-get update\nsudo apt-get install -y nvidia-container-toolkit-base\nsudo systemctl daemon-reload \nsudo systemctl restart docker\n安装完成后，可以使用以下命令编译镜像和启动容器：\n```\ndocker build -f Dockerfile-cuda -t chatglm-cuda:latest .\ndocker run --gpus all -d --name chatglm -p 7860:7860  chatglm-cuda:latest' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='若要使用离线模型，请配置好模型路径，然后此repo挂载到Container' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='docker run --gpus all -d --name chatglm -p 7860:7860 -v ~/github/langchain-ChatGLM:/chatGLM  chatglm-cuda:latest\n```' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='开发部署' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='软件需求' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='本项目已在 Python 3.8.1 - 3.10，CUDA 11.7 环境下完成测试。已在 Windows、ARM 架构的 macOS、Linux 系统中完成测试。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='vue前端需要node18环境' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='从本地加载模型' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='请参考 THUDM/ChatGLM-6B#从本地加载模型' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='1. 安装环境' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='参见 安装指南。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='2. 设置模型默认参数' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='在开始执行 Web UI 或命令行交互前，请先检查 configs/model_config.py 中的各项模型参数设计是否符合需求。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='如需通过 fastchat 以 api 形式调用 llm，请参考 fastchat 调用实现' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='3. 执行脚本体验 Web UI 或命令行交互' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='注：鉴于环境部署过程中可能遇到问题，建议首先测试命令行脚本。建议命令行脚本测试可正常运行后再运行 Web UI。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='执行 cli_demo.py 脚本体验命令行交互：\nshell\n$ python cli_demo.py' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='或执行 webui.py 脚本体验 Web 交互' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='shell\n$ python webui.py' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='或执行 api.py 利用 fastapi 部署 API\nshell\n$ python api.py\n或成功部署 API 后，执行以下脚本体验基于 VUE 的前端页面\n```shell\n$ cd views' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='$ pnpm i' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ npm run dev\n```' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Web UI 可以实现如下功能：' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='运行前自动读取configs/model_config.py中LLM及Embedding模型枚举及默认模型设置运行模型，如需重新加载模型，可在 模型配置 Tab 重新选择后点击 重新加载模型 进行模型加载；' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='可手动调节保留对话历史长度、匹配知识库文段数量，可根据显存大小自行调节；' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='对话 Tab 具备模式选择功能，可选择 LLM对话 与 知识库问答 模式进行对话，支持流式对话；' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='添加 配置知识库 功能，支持选择已有知识库或新建知识库，并可向知识库中新增上传文件/文件夹，使用文件上传组件选择好文件后点击 上传文件并加载知识库，会将所选上传文档数据加载至知识库中，并基于更新后知识库进行问答；' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='新增 知识库测试 Beta Tab，可用于测试不同文本切分方法与检索相关度阈值设置，暂不支持将测试参数作为 对话 Tab 设置参数。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='后续版本中将会增加对知识库的修改或删除，及知识库中已导入文件的查看。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='常见问题' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='参见 常见问题。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Demo' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='以问题chatglm-6b 的局限性具体体现在哪里，如何实现改进为例：' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='未使用 langchain 接入本地文档时：' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B 是一个基于 GPT-3 的聊天机器人,它的局限性主要体现在以下几个方面:\n1. 语言模型的精度:GPT-3 是一种大型的语言模型,它的精度比较高,但是仍然有一些局限性。例如,它可能无法准确地理解某些方言、口音或者复杂的句子结构。\n2. 知识图谱的完整性:GPT-3 可以生成一些知识图谱,但是其完整性和准确性可能不够。例如,它可能无法准确地理解某些领域的专业知识和术语。\n3. 对话生成的连贯性:GPT-3 可以生成一些连贯的对话,但是其生成的对话可能不够自然。例如,它可能会生成一些虚假的、不连贯的对话或者误解用户的意图。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='为了改进 ChatGLM-6B,可以考虑以下几个方面:\n1. 提高语言模型的精度:可以通过增加训练数据、使用更好的语言模型架构、优化模型训练过程等方式来提高语言模型的精度。\n2. 增强知识图谱的完整性:可以通过增加知识图谱的维度、使用更好的知识图谱构建方法、优化知识图谱的匹配算法等方式来增强知识图谱的完整性。\n3. 提高对话生成的连贯性:可以通过增加对话生成模型的上下文信息、使用更好的上下文信息提取方法、优化对话生成模型的算法等方式来提高对话生成的连贯性。\n4. 引入更多的人类反馈:人类反馈可以帮助 ChatGLM-6B 更好地理解用户的意图和需求,从而提高对话生成的质量和准确性。可以通过引入更多的人类客服、使用人类反馈收集器等方式来引入更多的人类反馈。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='使用 langchain 接入 ChatGLM-6B 项目的 README.md 文件后 ChatGLM 的回答：' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B 是一个基于深度学习的自然语言处理模型,它在回答问题方面表现出色。但是,它也有一些局限性,具体如下:\n1. 语言理解有限:ChatGLM-6B 只学习了中文自然语言,对于其他语言可能会存在理解上的局限性。\n2. 知识储备不足:ChatGLM-6B 的训练数据集只包含了中文语料,因此它可能无法回答一些非中文的问题或者某些特定领域的问题。\n3. 数据量有限:ChatGLM-6B 的训练数据集只有几百万条记录,因此它可能无法回答一些非常具体或者复杂的问题。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='为了改进 ChatGLM-6B,可以考虑以下几个方面:\n1. 学习更多的语言知识:可以学习其他语言的自然语言处理技术,扩大语言理解的范围。\n2. 扩大知识储备:可以收集更多的中文语料,或者使用其他语言的数据集来扩充知识储备。\n3. 增加数据量:可以使用更大的数据集来训练 ChatGLM-6B,提高模型的表现。\n4. 引入更多的评估指标:可以引入更多的评估指标来评估模型的表现,从而发现 ChatGLM-6B 存在的不足和局限性。\n5. 改进模型架构:可以改进 ChatGLM-6B 的模型架构,提高模型的性能和表现。例如,可以使用更大的神经网络或者改进的卷积神经网络结构。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='路线图' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='[ ] Langchain 应用' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 接入非结构化文档（已支持 md、pdf、docx、txt 文件格式）' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] jpg 与 png 格式图片的 OCR 文字识别' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 搜索引擎接入' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 本地网页接入' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 结构化数据接入（如 csv、Excel、SQL 等）' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 知识图谱/图数据库接入' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Agent 实现' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 增加更多 LLM 模型支持' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm2-6b' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b-int8' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b-int4' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b-int4-qe' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] ClueAI/ChatYuan-large-v2' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] fnlp/moss-moon-003-sft' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] bigscience/bloomz-7b1' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] bigscience/bloom-3b' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] baichuan-inc/baichuan-7B' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] lmsys/vicuna-13b-delta-v1.1' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 支持通过调用 fastchat api 调用 llm' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 增加更多 Embedding 模型支持' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] nghuyong/ernie-3.0-nano-zh' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] nghuyong/ernie-3.0-base-zh' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] shibing624/text2vec-base-chinese' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] GanymedeNil/text2vec-large-chinese' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] moka-ai/m3e-small' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] moka-ai/m3e-base' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Web UI' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 基于 gradio 实现 Web UI DEMO' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 基于 streamlit 实现 Web UI DEMO' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 添加输出内容及错误提示' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 引用标注' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 增加知识库管理\n[x] 选择知识库开始问答\n[x] 上传文件/文件夹至知识库\n[x] 知识库测试\n[x] 删除知识库中文件' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 支持搜索引擎问答' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 增加 API 支持' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 利用 fastapi 实现 API 部署方式' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 实现调用 API 的 Web UI Demo' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] VUE 前端' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='项目交流群' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🎉 langchain-ChatGLM 项目微信交流群，如果你也对本项目感兴趣，欢迎加入群聊参与讨论交流。' metadata={'source': 'test_data/README.md', 'filename': 'README.md', 'file_directory': 'test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
filepath=./test_data/README.md,len=116
page_content='基于本地知识库的 ChatGLM 等大语言模型应用实现' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='介绍' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🌍 READ THIS IN ENGLISH' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🤖️ 一种利用 langchain 思想实现的基于本地知识库的问答应用，目标期望建立一套对中文场景与开源模型支持友好、可离线运行的知识库问答解决方案。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='GanymedeNil 的项目' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='document.ai 和' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='AlexZhangji 创建的' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B Pull Request 启发，建立了全流程可使用开源模型实现的本地知识库问答应用。现已支持使用' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B 等大语言模型直接接入，或通过' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='fastchat api 形式接入 Vicuna, Alpaca, LLaMA, Koala, RWKV 等模型。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='✅ 本项目中 Embedding 默认选用的是 GanymedeNil/text2vec-large-chinese，LLM 默认选用的是 ChatGLM-6B。依托上述模型，本项目可实现全部使用开源模型离线私有部署。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='⛓️ 本项目实现原理如下图所示，过程包括加载文件 -> 读取文本 -> 文本分割 -> 文本向量化 -> 问句向量化 -> 在文本向量中匹配出与问句向量最相似的top k个 -> 匹配出的文本作为上下文和问题一起添加到prompt中 -> 提交给LLM生成回答。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'UncategorizedText'}
page_content='📺 原理介绍视频' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='从文档处理角度来看，实现流程如下：' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🚩 本项目未涉及微调、训练过程，但可利用微调或训练对本项目效果进行优化。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🐳\xa0Docker镜像：registry.cn-beijing.aliyuncs.com/isafetech/chatmydata:1.0\xa0（感谢\xa0@InkSong🌲 ）' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='💻\xa0运行方式：docker\xa0run\xa0-d\xa0-p\xa080:7860\xa0--gpus\xa0all\xa0registry.cn-beijing.aliyuncs.com/isafetech/chatmydata:1.0' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='🌐 AutoDL 镜像' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='📓 ModelWhale 在线运行项目' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='变更日志' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='参见 版本更新日志。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='硬件需求' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B 模型硬件需求\n注：如未将模型下载至本地，请执行前检查$HOME/.cache/huggingface/文件夹剩余空间，模型文件下载至本地需要 15 GB 存储空间。\n注：一些其它的可选启动项见项目启动选项\n模型下载方法可参考 常见问题 中 Q8。\n| 量化等级   | 最低 GPU 显存（推理） | 最低 GPU 显存（高效参数微调） |\n| -------------- | ------------------------- | --------------------------------- |\n| FP16（无量化） | 13 GB                     | 14 GB                             |\n| INT8           | 8 GB                     | 9 GB                             |\n| INT4           | 6 GB                      | 7 GB                              |' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='MOSS 模型硬件需求\n注：如未将模型下载至本地，请执行前检查$HOME/.cache/huggingface/文件夹剩余空间，模型文件下载至本地需要 70 GB 存储空间\n模型下载方法可参考 常见问题 中 Q8。\n| 量化等级  | 最低 GPU 显存（推理） | 最低 GPU 显存（高效参数微调） |\n|-------------------|-----------------------| --------------------------------- |\n| FP16（无量化） | 68 GB             | -                     |\n| INT8      | 20 GB          | -                     |' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Embedding 模型硬件需求\n本项目中默认选用的 Embedding 模型 GanymedeNil/text2vec-large-chinese 约占用显存 3GB，也可修改为在 CPU 中运行。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Docker 整合包' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🐳 Docker镜像地址：registry.cn-beijing.aliyuncs.com/isafetech/chatmydata:1.0🌲' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='💻 一行命令运行：\nshell\ndocker run -d -p 80:7860 --gpus all registry.cn-beijing.aliyuncs.com/isafetech/chatmydata:1.0' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='该版本镜像大小25.2G，使用v0.1.16，以nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04为基础镜像' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='该版本内置两个embedding模型：m3e-base，text2vec-large-chinese，内置fastchat+chatglm-6b' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='该版本目标为方便一键部署使用，请确保您已经在Linux发行版上安装了NVIDIA驱动程序' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='请注意，您不需要在主机系统上安装CUDA工具包，但需要安装NVIDIA Driver以及NVIDIA Container Toolkit，请参考安装指南' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='首次拉取和启动均需要一定时间，首次启动时请参照下图使用docker logs -f <container id>查看日志' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='如遇到启动过程卡在Waiting..步骤，建议使用docker exec -it <container id> bash进入/logs/目录查看对应阶段日志' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Docker 部署' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='为了能让容器使用主机GPU资源，需要在主机上安装 NVIDIA Container Toolkit。具体安装步骤如下：\nshell\nsudo apt-get update\nsudo apt-get install -y nvidia-container-toolkit-base\nsudo systemctl daemon-reload \nsudo systemctl restart docker\n安装完成后，可以使用以下命令编译镜像和启动容器：\n```\ndocker build -f Dockerfile-cuda -t chatglm-cuda:latest .\ndocker run --gpus all -d --name chatglm -p 7860:7860  chatglm-cuda:latest' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='若要使用离线模型，请配置好模型路径，然后此repo挂载到Container' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='docker run --gpus all -d --name chatglm -p 7860:7860 -v ~/github/langchain-ChatGLM:/chatGLM  chatglm-cuda:latest\n```' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='开发部署' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='软件需求' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='本项目已在 Python 3.8.1 - 3.10，CUDA 11.7 环境下完成测试。已在 Windows、ARM 架构的 macOS、Linux 系统中完成测试。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='vue前端需要node18环境' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='从本地加载模型' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='请参考 THUDM/ChatGLM-6B#从本地加载模型' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='1. 安装环境' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='参见 安装指南。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='2. 设置模型默认参数' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='在开始执行 Web UI 或命令行交互前，请先检查 configs/model_config.py 中的各项模型参数设计是否符合需求。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='如需通过 fastchat 以 api 形式调用 llm，请参考 fastchat 调用实现' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='3. 执行脚本体验 Web UI 或命令行交互' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='注：鉴于环境部署过程中可能遇到问题，建议首先测试命令行脚本。建议命令行脚本测试可正常运行后再运行 Web UI。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='执行 cli_demo.py 脚本体验命令行交互：\nshell\n$ python cli_demo.py' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='或执行 webui.py 脚本体验 Web 交互' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='shell\n$ python webui.py' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='或执行 api.py 利用 fastapi 部署 API\nshell\n$ python api.py\n或成功部署 API 后，执行以下脚本体验基于 VUE 的前端页面\n```shell\n$ cd views' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='$ pnpm i' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ npm run dev\n```' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Web UI 可以实现如下功能：' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='运行前自动读取configs/model_config.py中LLM及Embedding模型枚举及默认模型设置运行模型，如需重新加载模型，可在 模型配置 Tab 重新选择后点击 重新加载模型 进行模型加载；' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='可手动调节保留对话历史长度、匹配知识库文段数量，可根据显存大小自行调节；' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='对话 Tab 具备模式选择功能，可选择 LLM对话 与 知识库问答 模式进行对话，支持流式对话；' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='添加 配置知识库 功能，支持选择已有知识库或新建知识库，并可向知识库中新增上传文件/文件夹，使用文件上传组件选择好文件后点击 上传文件并加载知识库，会将所选上传文档数据加载至知识库中，并基于更新后知识库进行问答；' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='新增 知识库测试 Beta Tab，可用于测试不同文本切分方法与检索相关度阈值设置，暂不支持将测试参数作为 对话 Tab 设置参数。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='后续版本中将会增加对知识库的修改或删除，及知识库中已导入文件的查看。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='常见问题' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='参见 常见问题。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Demo' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='以问题chatglm-6b 的局限性具体体现在哪里，如何实现改进为例：' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='未使用 langchain 接入本地文档时：' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B 是一个基于 GPT-3 的聊天机器人,它的局限性主要体现在以下几个方面:\n1. 语言模型的精度:GPT-3 是一种大型的语言模型,它的精度比较高,但是仍然有一些局限性。例如,它可能无法准确地理解某些方言、口音或者复杂的句子结构。\n2. 知识图谱的完整性:GPT-3 可以生成一些知识图谱,但是其完整性和准确性可能不够。例如,它可能无法准确地理解某些领域的专业知识和术语。\n3. 对话生成的连贯性:GPT-3 可以生成一些连贯的对话,但是其生成的对话可能不够自然。例如,它可能会生成一些虚假的、不连贯的对话或者误解用户的意图。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='为了改进 ChatGLM-6B,可以考虑以下几个方面:\n1. 提高语言模型的精度:可以通过增加训练数据、使用更好的语言模型架构、优化模型训练过程等方式来提高语言模型的精度。\n2. 增强知识图谱的完整性:可以通过增加知识图谱的维度、使用更好的知识图谱构建方法、优化知识图谱的匹配算法等方式来增强知识图谱的完整性。\n3. 提高对话生成的连贯性:可以通过增加对话生成模型的上下文信息、使用更好的上下文信息提取方法、优化对话生成模型的算法等方式来提高对话生成的连贯性。\n4. 引入更多的人类反馈:人类反馈可以帮助 ChatGLM-6B 更好地理解用户的意图和需求,从而提高对话生成的质量和准确性。可以通过引入更多的人类客服、使用人类反馈收集器等方式来引入更多的人类反馈。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='使用 langchain 接入 ChatGLM-6B 项目的 README.md 文件后 ChatGLM 的回答：' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B 是一个基于深度学习的自然语言处理模型,它在回答问题方面表现出色。但是,它也有一些局限性,具体如下:\n1. 语言理解有限:ChatGLM-6B 只学习了中文自然语言,对于其他语言可能会存在理解上的局限性。\n2. 知识储备不足:ChatGLM-6B 的训练数据集只包含了中文语料,因此它可能无法回答一些非中文的问题或者某些特定领域的问题。\n3. 数据量有限:ChatGLM-6B 的训练数据集只有几百万条记录,因此它可能无法回答一些非常具体或者复杂的问题。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='为了改进 ChatGLM-6B,可以考虑以下几个方面:\n1. 学习更多的语言知识:可以学习其他语言的自然语言处理技术,扩大语言理解的范围。\n2. 扩大知识储备:可以收集更多的中文语料,或者使用其他语言的数据集来扩充知识储备。\n3. 增加数据量:可以使用更大的数据集来训练 ChatGLM-6B,提高模型的表现。\n4. 引入更多的评估指标:可以引入更多的评估指标来评估模型的表现,从而发现 ChatGLM-6B 存在的不足和局限性。\n5. 改进模型架构:可以改进 ChatGLM-6B 的模型架构,提高模型的性能和表现。例如,可以使用更大的神经网络或者改进的卷积神经网络结构。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='路线图' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='[ ] Langchain 应用' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 接入非结构化文档（已支持 md、pdf、docx、txt 文件格式）' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] jpg 与 png 格式图片的 OCR 文字识别' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 搜索引擎接入' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 本地网页接入' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 结构化数据接入（如 csv、Excel、SQL 等）' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 知识图谱/图数据库接入' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Agent 实现' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 增加更多 LLM 模型支持' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm2-6b' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b-int8' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b-int4' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b-int4-qe' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] ClueAI/ChatYuan-large-v2' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] fnlp/moss-moon-003-sft' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] bigscience/bloomz-7b1' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] bigscience/bloom-3b' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] baichuan-inc/baichuan-7B' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] lmsys/vicuna-13b-delta-v1.1' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 支持通过调用 fastchat api 调用 llm' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 增加更多 Embedding 模型支持' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] nghuyong/ernie-3.0-nano-zh' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] nghuyong/ernie-3.0-base-zh' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] shibing624/text2vec-base-chinese' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] GanymedeNil/text2vec-large-chinese' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] moka-ai/m3e-small' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] moka-ai/m3e-base' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Web UI' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 基于 gradio 实现 Web UI DEMO' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 基于 streamlit 实现 Web UI DEMO' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 添加输出内容及错误提示' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 引用标注' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 增加知识库管理\n[x] 选择知识库开始问答\n[x] 上传文件/文件夹至知识库\n[x] 知识库测试\n[x] 删除知识库中文件' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 支持搜索引擎问答' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 增加 API 支持' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 利用 fastapi 实现 API 部署方式' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 实现调用 API 的 Web UI Demo' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] VUE 前端' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='项目交流群' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🎉 langchain-ChatGLM 项目微信交流群，如果你也对本项目感兴趣，欢迎加入群聊参与讨论交流。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
filepath=./test_data/README_en.md,len=120
page_content='ChatGLM Application with Local Knowledge Implementation' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Introduction' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🌍 中文文档' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🤖️ This is a ChatGLM application based on local knowledge, implemented using ChatGLM-6B and langchain.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content="💡 Inspired by document.ai and Alex Zhangji's ChatGLM-6B Pull Request, this project establishes a local knowledge question-answering application using open-source models." metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='✅ The embeddings used in this project are GanymedeNil/text2vec-large-chinese, and the LLM is ChatGLM-6B. Relying on these models, this project enables the use of open-source models for offline private deployment.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='⛓️ The implementation principle of this project is illustrated in the figure below. The process includes loading files -> reading text -> text segmentation -> text vectorization -> question vectorization -> matching the top k most similar text vectors to the question vector -> adding the matched text to prompt along with the question as context -> submitting to LLM to generate an answer.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='🚩 This project does not involve fine-tuning or training; however, fine-tuning or training can be employed to optimize the effectiveness of this project.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='📓 ModelWhale online notebook' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Changelog' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='[2023/04/15]' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'UncategorizedText'}
page_content='refactor the project structure to keep the command line demo cli_demo.py and the Web UI demo webui.py in the root directory.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Improve the Web UI by modifying it to first load the model according to the default option of configs/model_config.py after running the Web UI, and adding error messages, etc.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Update FAQ.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[2023/04/12]' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'UncategorizedText'}
page_content='Replaced the sample files in the Web UI to avoid issues with unreadable files due to encoding problems in Ubuntu;' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Replaced the prompt template in knowledge_based_chatglm.py to prevent confusion in the content returned by ChatGLM, which may arise from the prompt template containing Chinese and English bilingual text.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[2023/04/11]' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'UncategorizedText'}
page_content='Added Web UI V0.1 version (thanks to @liangtongt);' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Added Frequently Asked Questions in README.md (thanks to @calcitem and @bolongliu);' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Enhanced automatic detection for the availability of cuda, mps, and cpu for LLM and Embedding model running devices;' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Added a check for filepath in knowledge_based_chatglm.py. In addition to supporting single file import, it now supports a single folder path as input. After input, it will traverse each file in the folder and display a command-line message indicating the success of each file load.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[2023/04/09]' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Replaced the previously selected ChatVectorDBChain with RetrievalQA in langchain, effectively reducing the issue of stopping due to insufficient video memory after asking 2-3 times;' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Added EMBEDDING_MODEL, VECTOR_SEARCH_TOP_K, LLM_MODEL, LLM_HISTORY_LEN, REPLY_WITH_SOURCE parameter value settings in knowledge_based_chatglm.py;' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Added chatglm-6b-int4 and chatglm-6b-int4-qe, which require less GPU memory, as LLM model options;' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Corrected code errors in README.md (thanks to @calcitem).' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[2023/04/07]' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'UncategorizedText'}
page_content='Resolved the issue of doubled video memory usage when loading the ChatGLM model (thanks to @suc16 and @myml);' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Added a mechanism to clear video memory;' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Added nghuyong/ernie-3.0-nano-zh and nghuyong/ernie-3.0-base-zh as Embedding model options, which consume less video memory resources than GanymedeNil/text2vec-large-chinese (thanks to @lastrei).' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='How to Use' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Hardware Requirements' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B Model Hardware Requirements\n| Quantization Level | Minimum GPU Memory (inference) | Minimum GPU Memory (efficient parameter fine-tuning) |\n | -------------- | ------------------------- | --------------------------------- |\n | FP16 (no quantization) | 13 GB | 14 GB |\n | INT8 | 8 GB | 9 GB |\n | INT4 | 6 GB | 7 GB |' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Embedding Model Hardware Requirements\nThe default Embedding model GanymedeNil/text2vec-large-chinese in this project occupies around 3GB of video memory and can also be configured to run on a CPU.\nSoftware Requirements' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='This repository has been tested with Python 3.8 and CUDA 11.7 environments.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='1. Setting up the environment' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Environment check' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='```shell' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='First, make sure your machine has Python 3.8 or higher installed' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ python --version\nPython 3.8.13' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='If your version is lower, you can use conda to install the environment' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'UncategorizedText'}
page_content='$ conda create -p /your_path/env_name python=3.8' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Activate the environment' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ source activate /your_path/env_name' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Deactivate the environment' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ source deactivate /your_path/env_name' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Remove the environment' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ conda env remove -p  /your_path/env_name\n```' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Project dependencies' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='```shell' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Clone the repository' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ git clone https://github.com/imClumsyPanda/langchain-ChatGLM.git' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Install dependencies' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ pip install -r requirements.txt\n```' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Note: When using langchain.document_loaders.UnstructuredFileLoader for unstructured file integration, you may need to install other dependency packages according to the documentation. Please refer to langchain documentation.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='2. Run Scripts to Experience Web UI or Command Line Interaction' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Execute webui.py script to experience Web interaction \n```commandline\npython webui.py' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Or execute [api.py](api.py) script to deploy web api.shell\n$ python api.py\n``\nNote: Before executing, check the remaining space in the$HOME/.cache/huggingface/` folder, at least 15G.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Or execute following command to run VUE after api.py executed\n```shell\n$ cd views' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='$ pnpm i' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ npm run dev\n```' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='VUE interface screenshots:' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Web UI interface screenshots:' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='The Web UI supports the following features:' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Automatically reads the LLM and embedding model enumerations in configs/model_config.py, allowing you to select and reload the model by clicking 重新加载模型.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='The length of retained dialogue history can be manually adjusted according to the available video memory.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Adds a file upload function. Select the uploaded file through the drop-down box, click 加载文件 to load the file, and change the loaded file at any time during the process.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Alternatively, execute the knowledge_based_chatglm.py script to experience command line interaction:' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='commandline\npython knowledge_based_chatglm.py' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='FAQ' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Q1: What file formats does this project support?' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='A1: Currently, this project has been tested with txt, docx, and md file formats. For more file formats, please refer to the langchain documentation. It is known that if the document contains special characters, there might be issues with loading the file.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Q2: How can I resolve the detectron2 dependency issue when reading specific file formats?' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='A2: As the installation process for this package can be problematic and it is only required for some file formats, it is not included in requirements.txt. You can install it with the following command:' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='commandline\npip install "detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2"' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Q3: How can I solve the Resource punkt not found. error?' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='A3: Unzip the packages/tokenizers folder from https://github.com/nltk/nltk_data/raw/gh-pages/packages/tokenizers/punkt.zip, and place it in the nltk_data/tokenizers storage path.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='The nltk_data storage path can be found using nltk.data.path.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Q4: How can I solve the Resource averaged_perceptron_tagger not found. error?' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='A4: Download https://github.com/nltk/nltk_data/blob/gh-pages/packages/taggers/averaged_perceptron_tagger.zip, extract it, and place it in the nltk_data/taggers storage path.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='The nltk_data storage path can be found using nltk.data.path.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Q5: Can this project run in Google Colab?' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content="A5: You can try running the chatglm-6b-int4 model in Google Colab. Please note that if you want to run the Web UI in Colab, you need to set the share parameter in demo.queue(concurrency_count=3).launch(server_name='0.0.0.0', share=False, inbrowser=False) to True." metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='This issue is related to the system environment. For more details, please refer to Issues with installing packages using pip in Anaconda.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='DEMO' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Using the question "What are the limitations of ChatGLM-6B and how can they be improved?" as an example:' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Without using langchain to access local documents:' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='ChatGLM-6B is a chatbot based on GPT-3, and its limitations are mainly reflected in the following aspects:' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Language model accuracy: Although GPT-3 is a large language model with relatively high accuracy, it still has some limitations. For instance, it may not be able to accurately understand certain dialects, accents, or complex sentence structures.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Completeness of the knowledge graph: GPT-3 can generate some knowledge graphs, but its completeness and accuracy may not be sufficient. For example, it may struggle to accurately understand specific domain expertise and terminology.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content="Coherence of dialogue generation: While GPT-3 can generate somewhat coherent dialogues, they may not always be natural. For instance, it may generate false, incoherent dialogue or misinterpret the user's intent." metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='To improve ChatGLM-6B, consider the following aspects:' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Enhance the accuracy of the language model: The accuracy of the language model can be improved by increasing the training data, using better language model architectures, and optimizing the model training process.' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content="Strengthen the integrity of the knowledge graph: The integrity of the knowledge graph can be enhanced by increasing its dimensions, employing better knowledge graph construction methods, and optimizing the knowledge graph's matching algorithm." metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content="Boost the coherence of dialogue generation: The coherence of dialogue generation can be improved by augmenting the context information of the dialogue generation model, utilizing better context information extraction methods, and optimizing the dialogue generation model's algorithm." metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content="Incorporate more human feedback: Human feedback can help ChatGLM-6B better understand users' intentions and needs, thereby improving the quality and accuracy of dialogue generation. More human feedback can be introduced by involving more human agents and using human feedback collectors." metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content="ChatGLM's answer after using LangChain to access the README.md file of the ChatGLM-6B project:" metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content="ChatGLM-6B is a deep learning-based natural language processing model that excels at answering questions. However, it also has some limitations, as follows:\n1. Limited language understanding: ChatGLM-6B has been primarily trained on Chinese natural language, and its understanding of other languages may be limited.\n2. Insufficient knowledge base: The training dataset of ChatGLM-6B contains only a Chinese corpus, so it may not be able to answer non-Chinese questions or queries in specific domains.\n3. Limited data volume: ChatGLM-6B's training dataset has only a few million records, which may hinder its ability to answer very specific or complex questions." metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content="To improve ChatGLM-6B, consider the following aspects:\n1. Expand language knowledge: Learn natural language processing techniques in other languages to broaden the model's language understanding capabilities.\n2. Broaden the knowledge base: Collect more Chinese corpora or use datasets in other languages to expand the model's knowledge base.\n3. Increase data volume: Use larger datasets to train ChatGLM-6B, which can improve the model's performance.\n4. Introduce more evaluation metrics: Incorporate additional evaluation metrics to assess the model's performance, which can help identify the shortcomings and limitations of ChatGLM-6B.\n5. Enhance the model architecture: Improve ChatGLM-6B's model architecture to boost its performance and capabilities. For example, employ larger neural networks or refined convolutional neural network structures." metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='Roadmap' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='[x] Implement LangChain + ChatGLM-6B for local knowledge application' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] Unstructured file access based on langchain' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x].md' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x].pdf' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x].docx' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x].txt' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Add support for more LLM models' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b-int4' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b-int4-qe' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Add Web UI DEMO' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] Implement Web UI DEMO using Gradio' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] Add output and error messages' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] Citation callout' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Knowledge base management\n[x] QA based on selected knowledge base\n[x] Add files/folder to knowledge base\n[ ] Add files/folder to knowledge base' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Implement Web UI DEMO using Streamlit' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Add support for API deployment' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] Use fastapi to implement API' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Implement Web UI DEMO for API calls' metadata={'source': './test_data/README_en.md', 'filename': 'README_en.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
filepath=./test_data/README.md,len=116
page_content='基于本地知识库的 ChatGLM 等大语言模型应用实现' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='介绍' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🌍 READ THIS IN ENGLISH' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🤖️ 一种利用 langchain 思想实现的基于本地知识库的问答应用，目标期望建立一套对中文场景与开源模型支持友好、可离线运行的知识库问答解决方案。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='GanymedeNil 的项目' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='document.ai 和' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='AlexZhangji 创建的' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B Pull Request 启发，建立了全流程可使用开源模型实现的本地知识库问答应用。现已支持使用' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B 等大语言模型直接接入，或通过' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='fastchat api 形式接入 Vicuna, Alpaca, LLaMA, Koala, RWKV 等模型。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='✅ 本项目中 Embedding 默认选用的是 GanymedeNil/text2vec-large-chinese，LLM 默认选用的是 ChatGLM-6B。依托上述模型，本项目可实现全部使用开源模型离线私有部署。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='⛓️ 本项目实现原理如下图所示，过程包括加载文件 -> 读取文本 -> 文本分割 -> 文本向量化 -> 问句向量化 -> 在文本向量中匹配出与问句向量最相似的top k个 -> 匹配出的文本作为上下文和问题一起添加到prompt中 -> 提交给LLM生成回答。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'UncategorizedText'}
page_content='📺 原理介绍视频' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='从文档处理角度来看，实现流程如下：' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🚩 本项目未涉及微调、训练过程，但可利用微调或训练对本项目效果进行优化。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🐳\xa0Docker镜像：registry.cn-beijing.aliyuncs.com/isafetech/chatmydata:1.0\xa0（感谢\xa0@InkSong🌲 ）' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='💻\xa0运行方式：docker\xa0run\xa0-d\xa0-p\xa080:7860\xa0--gpus\xa0all\xa0registry.cn-beijing.aliyuncs.com/isafetech/chatmydata:1.0' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='🌐 AutoDL 镜像' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='📓 ModelWhale 在线运行项目' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='变更日志' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='参见 版本更新日志。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='硬件需求' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B 模型硬件需求\n注：如未将模型下载至本地，请执行前检查$HOME/.cache/huggingface/文件夹剩余空间，模型文件下载至本地需要 15 GB 存储空间。\n注：一些其它的可选启动项见项目启动选项\n模型下载方法可参考 常见问题 中 Q8。\n| 量化等级   | 最低 GPU 显存（推理） | 最低 GPU 显存（高效参数微调） |\n| -------------- | ------------------------- | --------------------------------- |\n| FP16（无量化） | 13 GB                     | 14 GB                             |\n| INT8           | 8 GB                     | 9 GB                             |\n| INT4           | 6 GB                      | 7 GB                              |' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='MOSS 模型硬件需求\n注：如未将模型下载至本地，请执行前检查$HOME/.cache/huggingface/文件夹剩余空间，模型文件下载至本地需要 70 GB 存储空间\n模型下载方法可参考 常见问题 中 Q8。\n| 量化等级  | 最低 GPU 显存（推理） | 最低 GPU 显存（高效参数微调） |\n|-------------------|-----------------------| --------------------------------- |\n| FP16（无量化） | 68 GB             | -                     |\n| INT8      | 20 GB          | -                     |' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Embedding 模型硬件需求\n本项目中默认选用的 Embedding 模型 GanymedeNil/text2vec-large-chinese 约占用显存 3GB，也可修改为在 CPU 中运行。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Docker 整合包' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🐳 Docker镜像地址：registry.cn-beijing.aliyuncs.com/isafetech/chatmydata:1.0🌲' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='💻 一行命令运行：\nshell\ndocker run -d -p 80:7860 --gpus all registry.cn-beijing.aliyuncs.com/isafetech/chatmydata:1.0' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='该版本镜像大小25.2G，使用v0.1.16，以nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04为基础镜像' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='该版本内置两个embedding模型：m3e-base，text2vec-large-chinese，内置fastchat+chatglm-6b' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='该版本目标为方便一键部署使用，请确保您已经在Linux发行版上安装了NVIDIA驱动程序' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='请注意，您不需要在主机系统上安装CUDA工具包，但需要安装NVIDIA Driver以及NVIDIA Container Toolkit，请参考安装指南' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='首次拉取和启动均需要一定时间，首次启动时请参照下图使用docker logs -f <container id>查看日志' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='如遇到启动过程卡在Waiting..步骤，建议使用docker exec -it <container id> bash进入/logs/目录查看对应阶段日志' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='Docker 部署' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='为了能让容器使用主机GPU资源，需要在主机上安装 NVIDIA Container Toolkit。具体安装步骤如下：\nshell\nsudo apt-get update\nsudo apt-get install -y nvidia-container-toolkit-base\nsudo systemctl daemon-reload \nsudo systemctl restart docker\n安装完成后，可以使用以下命令编译镜像和启动容器：\n```\ndocker build -f Dockerfile-cuda -t chatglm-cuda:latest .\ndocker run --gpus all -d --name chatglm -p 7860:7860  chatglm-cuda:latest' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='若要使用离线模型，请配置好模型路径，然后此repo挂载到Container' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='docker run --gpus all -d --name chatglm -p 7860:7860 -v ~/github/langchain-ChatGLM:/chatGLM  chatglm-cuda:latest\n```' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='开发部署' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='软件需求' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='本项目已在 Python 3.8.1 - 3.10，CUDA 11.7 环境下完成测试。已在 Windows、ARM 架构的 macOS、Linux 系统中完成测试。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='vue前端需要node18环境' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='从本地加载模型' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='请参考 THUDM/ChatGLM-6B#从本地加载模型' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='1. 安装环境' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='参见 安装指南。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='2. 设置模型默认参数' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='在开始执行 Web UI 或命令行交互前，请先检查 configs/model_config.py 中的各项模型参数设计是否符合需求。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='如需通过 fastchat 以 api 形式调用 llm，请参考 fastchat 调用实现' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='3. 执行脚本体验 Web UI 或命令行交互' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='注：鉴于环境部署过程中可能遇到问题，建议首先测试命令行脚本。建议命令行脚本测试可正常运行后再运行 Web UI。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='执行 cli_demo.py 脚本体验命令行交互：\nshell\n$ python cli_demo.py' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='或执行 webui.py 脚本体验 Web 交互' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='shell\n$ python webui.py' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='或执行 api.py 利用 fastapi 部署 API\nshell\n$ python api.py\n或成功部署 API 后，执行以下脚本体验基于 VUE 的前端页面\n```shell\n$ cd views' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='$ pnpm i' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='$ npm run dev\n```' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Web UI 可以实现如下功能：' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='运行前自动读取configs/model_config.py中LLM及Embedding模型枚举及默认模型设置运行模型，如需重新加载模型，可在 模型配置 Tab 重新选择后点击 重新加载模型 进行模型加载；' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='可手动调节保留对话历史长度、匹配知识库文段数量，可根据显存大小自行调节；' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='对话 Tab 具备模式选择功能，可选择 LLM对话 与 知识库问答 模式进行对话，支持流式对话；' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='添加 配置知识库 功能，支持选择已有知识库或新建知识库，并可向知识库中新增上传文件/文件夹，使用文件上传组件选择好文件后点击 上传文件并加载知识库，会将所选上传文档数据加载至知识库中，并基于更新后知识库进行问答；' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='新增 知识库测试 Beta Tab，可用于测试不同文本切分方法与检索相关度阈值设置，暂不支持将测试参数作为 对话 Tab 设置参数。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='后续版本中将会增加对知识库的修改或删除，及知识库中已导入文件的查看。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='常见问题' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='参见 常见问题。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='Demo' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='以问题chatglm-6b 的局限性具体体现在哪里，如何实现改进为例：' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='未使用 langchain 接入本地文档时：' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B 是一个基于 GPT-3 的聊天机器人,它的局限性主要体现在以下几个方面:\n1. 语言模型的精度:GPT-3 是一种大型的语言模型,它的精度比较高,但是仍然有一些局限性。例如,它可能无法准确地理解某些方言、口音或者复杂的句子结构。\n2. 知识图谱的完整性:GPT-3 可以生成一些知识图谱,但是其完整性和准确性可能不够。例如,它可能无法准确地理解某些领域的专业知识和术语。\n3. 对话生成的连贯性:GPT-3 可以生成一些连贯的对话,但是其生成的对话可能不够自然。例如,它可能会生成一些虚假的、不连贯的对话或者误解用户的意图。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='为了改进 ChatGLM-6B,可以考虑以下几个方面:\n1. 提高语言模型的精度:可以通过增加训练数据、使用更好的语言模型架构、优化模型训练过程等方式来提高语言模型的精度。\n2. 增强知识图谱的完整性:可以通过增加知识图谱的维度、使用更好的知识图谱构建方法、优化知识图谱的匹配算法等方式来增强知识图谱的完整性。\n3. 提高对话生成的连贯性:可以通过增加对话生成模型的上下文信息、使用更好的上下文信息提取方法、优化对话生成模型的算法等方式来提高对话生成的连贯性。\n4. 引入更多的人类反馈:人类反馈可以帮助 ChatGLM-6B 更好地理解用户的意图和需求,从而提高对话生成的质量和准确性。可以通过引入更多的人类客服、使用人类反馈收集器等方式来引入更多的人类反馈。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='使用 langchain 接入 ChatGLM-6B 项目的 README.md 文件后 ChatGLM 的回答：' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='ChatGLM-6B 是一个基于深度学习的自然语言处理模型,它在回答问题方面表现出色。但是,它也有一些局限性,具体如下:\n1. 语言理解有限:ChatGLM-6B 只学习了中文自然语言,对于其他语言可能会存在理解上的局限性。\n2. 知识储备不足:ChatGLM-6B 的训练数据集只包含了中文语料,因此它可能无法回答一些非中文的问题或者某些特定领域的问题。\n3. 数据量有限:ChatGLM-6B 的训练数据集只有几百万条记录,因此它可能无法回答一些非常具体或者复杂的问题。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='为了改进 ChatGLM-6B,可以考虑以下几个方面:\n1. 学习更多的语言知识:可以学习其他语言的自然语言处理技术,扩大语言理解的范围。\n2. 扩大知识储备:可以收集更多的中文语料,或者使用其他语言的数据集来扩充知识储备。\n3. 增加数据量:可以使用更大的数据集来训练 ChatGLM-6B,提高模型的表现。\n4. 引入更多的评估指标:可以引入更多的评估指标来评估模型的表现,从而发现 ChatGLM-6B 存在的不足和局限性。\n5. 改进模型架构:可以改进 ChatGLM-6B 的模型架构,提高模型的性能和表现。例如,可以使用更大的神经网络或者改进的卷积神经网络结构。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'NarrativeText'}
page_content='路线图' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='[ ] Langchain 应用' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 接入非结构化文档（已支持 md、pdf、docx、txt 文件格式）' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] jpg 与 png 格式图片的 OCR 文字识别' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 搜索引擎接入' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 本地网页接入' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 结构化数据接入（如 csv、Excel、SQL 等）' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 知识图谱/图数据库接入' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Agent 实现' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 增加更多 LLM 模型支持' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm2-6b' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b-int8' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b-int4' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] THUDM/chatglm-6b-int4-qe' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] ClueAI/ChatYuan-large-v2' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] fnlp/moss-moon-003-sft' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] bigscience/bloomz-7b1' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] bigscience/bloom-3b' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] baichuan-inc/baichuan-7B' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] lmsys/vicuna-13b-delta-v1.1' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 支持通过调用 fastchat api 调用 llm' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 增加更多 Embedding 模型支持' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] nghuyong/ernie-3.0-nano-zh' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] nghuyong/ernie-3.0-base-zh' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] shibing624/text2vec-base-chinese' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] GanymedeNil/text2vec-large-chinese' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] moka-ai/m3e-small' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] moka-ai/m3e-base' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] Web UI' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 基于 gradio 实现 Web UI DEMO' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 基于 streamlit 实现 Web UI DEMO' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 添加输出内容及错误提示' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 引用标注' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 增加知识库管理\n[x] 选择知识库开始问答\n[x] 上传文件/文件夹至知识库\n[x] 知识库测试\n[x] 删除知识库中文件' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 支持搜索引擎问答' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 增加 API 支持' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] 利用 fastapi 实现 API 部署方式' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[ ] 实现调用 API 的 Web UI Demo' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='[x] VUE 前端' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'ListItem'}
page_content='项目交流群' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
page_content='🎉 langchain-ChatGLM 项目微信交流群，如果你也对本项目感兴趣，欢迎加入群聊参与讨论交流。' metadata={'source': './test_data/README.md', 'filename': 'README.md', 'file_directory': './test_data', 'filetype': 'text/markdown', 'page_number': 1, 'category': 'Title'}
